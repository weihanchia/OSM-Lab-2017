{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Set 3 for OSM \n",
    "\n",
    "### Dynamic Programming with John Stachurski\n",
    "\n",
    "### Solutions by Wei Han Chia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises for the [OSM](https://bfi.uchicago.edu/osm) bootcamp dynamic programming section.\n",
    "\n",
    "We will use the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import quantecon as qe\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.\n",
    "\n",
    "Using Numba, as discussed in [this lecture](https://lectures.quantecon.org/py/need_for_speed.html), write your own version of NumPy's [interp](https://docs.scipy.org/doc/numpy/reference/generated/numpy.interp.html) function, specializing in linear interpolation in one dimension.  \n",
    "\n",
    "Note that NumPy's function is compiled native machine code and hence is fast.  But try to beat if you can, at least in some scenarios, by using Numba to speed up your code.  Show a time comparison between the two functions, for some suitable choice of test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import timeit\n",
    "\n",
    "def lininterp(x, xp, yp):\n",
    "    y = np.ones_like(x)\n",
    "    xlen = len(x)\n",
    "    length = len(yp)\n",
    "    for j in range(0,xlen):\n",
    "        xtemp = x[j]\n",
    "        if xtemp < xp[0]:\n",
    "            y[j] = yp[0]\n",
    "        elif xtemp > xp[length-1]:\n",
    "            y[j] = yp[length-1]\n",
    "        else:\n",
    "            for i in range(0,length-2):\n",
    "                if xtemp > xp[i] and xtemp < xp[i+1]:\n",
    "                    y[j] = (yp[i]*(xp[i+1] - xtemp) + yp[i+1]*(xtemp - xp[i]))/(xp[i+1] - xp[i])\n",
    "    return y\n",
    "\n",
    "# Lets test interpolation speed on a quadratic function\n",
    "xp_test = np.linspace(2,7,1000)\n",
    "yp_test = xp_test ** 2\n",
    "x_test = np.linspace(3.5,5,100)\n",
    "\n",
    "lininterp_numba = jit(lininterp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time without JIT:  0.22047310671769083\n",
      "Time with JIT:  0.000943280931096524\n",
      "Time with np.interp:  0.000750226026866585\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "lininterp(x_test,xp_test,yp_test)\n",
    "print(\"Time without JIT: \", timeit.default_timer() - start_time)\n",
    "\n",
    "start_time_jit = timeit.default_timer()\n",
    "lininterp_numba(x_test,xp_test,yp_test)\n",
    "print(\"Time with JIT: \", timeit.default_timer() - start_time_jit)\n",
    "\n",
    "start_time_np = timeit.default_timer()\n",
    "np.interp(x_test,xp_test,yp_test)\n",
    "print(\"Time with np.interp: \", timeit.default_timer() - start_time_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With numba, the timing of our homemade linear interpolation function approaches the same speed as that of np.interp. This is a significant speedup from the time without numba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Using your \"Numbafied\" linear interpolation function, try to use Numba to additionally speed up the endogenous grid method code from [this lecture](https://lectures.quantecon.org/py/egm_policy_iter.html).  Use CRRA utility and Cobb-Douglas production, as in that lecture, with the following parameter values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I didn't get much speed up.  I think because the outer loops don't matter much for speed, and hence it doesn't gain us much when we compile them.  \n",
    "\n",
    "See how you go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import quantecon as qe\n",
    "\n",
    "## Define the model\n",
    "\n",
    "alpha = 0.65\n",
    "beta = 0.95\n",
    "mu = 0\n",
    "s = 0.1\n",
    "grid_min = 1e-6\n",
    "grid_max = 4\n",
    "grid_size = 200\n",
    "shock_size = 250\n",
    "\n",
    "gamma = 1.5   # Preference parameter\n",
    "gamma_inv = 1 / gamma\n",
    "\n",
    "def f(k):\n",
    "    return k**alpha\n",
    "\n",
    "def f_prime(k):\n",
    "    return alpha * k**(alpha - 1)\n",
    "\n",
    "def u(c):\n",
    "    return (c**(1 - gamma) - 1) / (1 - gamma)\n",
    "\n",
    "def u_prime(c):\n",
    "    return c**(-gamma)\n",
    "\n",
    "def u_prime_inv(c):\n",
    "    return c**(-gamma_inv)\n",
    "\n",
    "k_grid = np.linspace(grid_min, grid_max, grid_size)\n",
    "shocks = np.exp(mu + s * np.random.randn(shock_size))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def coleman_egm(g, k_grid, beta, u_prime, u_prime_inv, f, f_prime, shocks):\n",
    "    \"\"\"\n",
    "    The approximate Coleman operator, updated using the endogenous grid\n",
    "    method.  \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    g : function\n",
    "        The current guess of the policy function\n",
    "    k_grid : array_like(float, ndim=1)\n",
    "        The set of *exogenous* grid points, for capital k = y - c\n",
    "    beta : scalar\n",
    "        The discount factor\n",
    "    u_prime : function\n",
    "        The derivative u'(c) of the utility function\n",
    "    u_prime_inv : function\n",
    "        The inverse of u' (which exists by assumption)\n",
    "    f : function\n",
    "        The production function f(k)\n",
    "    f_prime : function\n",
    "        The derivative f'(k)\n",
    "    shocks : numpy array\n",
    "        An array of draws from the shock, for Monte Carlo integration (to\n",
    "        compute expectations).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Allocate memory for value of consumption on endogenous grid points\n",
    "    c = np.empty_like(k_grid)  \n",
    "\n",
    "    # Solve for updated consumption value\n",
    "    for i, k in enumerate(k_grid):\n",
    "        vals = u_prime(g(f(k) * shocks)) * f_prime(k) * shocks\n",
    "        c[i] = u_prime_inv(beta * np.mean(vals))\n",
    "    \n",
    "    # Determine endogenous grid\n",
    "    y = k_grid + c  # y_i = k_i + c_i\n",
    "\n",
    "    # Update policy function and return\n",
    "    Kg = lambda x: lininterp_numba(x, y, c)\n",
    "    return Kg\n",
    "\n",
    "def crra_coleman_egm(g):\n",
    "    return coleman_egm(g, k_grid, beta, u_prime, u_prime_inv, f, f_prime, shocks)\n",
    "\n",
    "sim_length = 20\n",
    "\n",
    "crra_coleman_egm_numba = jit(crra_coleman_egm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timing policy function iteration with endogenous grid\n",
      "TOC: Elapsed: 0.47135186195373535 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47135186195373535"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Timing policy function iteration with endogenous grid\")\n",
    "g_init_egm = lambda x: x\n",
    "g = g_init_egm\n",
    "qe.util.tic()\n",
    "for i in range(sim_length):\n",
    "    new_g = crra_coleman_egm_numba(g)\n",
    "    g = new_g\n",
    "qe.util.toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't seem like numba speeds up the implementation for the egp method significantly compared to the results presented in the lecture notes. In fact it would appear that our inefficient linear interpolation function slows down the overall speed of the endogenous grid method slightly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
